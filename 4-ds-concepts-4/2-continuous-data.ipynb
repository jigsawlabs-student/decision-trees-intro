{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Continuous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, let's use a decision tree to work with a larger dataset of movie data.  This is an optional reading, as the main concepts of decision trees remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we'll get started by loading up our data.  Now that data that we'll use is a [set of movie data](https://github.com/fivethirtyeight/data/tree/master/bechdel) put together by the website 538.  Because we haven't learned anything about data cleaning yet, we'll work with a cleaned up version of this data.  Time to load it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action</td>\n",
       "      <td>237000000</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>2787965087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>300000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>961000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>Action</td>\n",
       "      <td>245000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>880674609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Action</td>\n",
       "      <td>250000000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>1084939099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>Action</td>\n",
       "      <td>260000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>284139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>258000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>890871626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>Animation</td>\n",
       "      <td>260000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>591794936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action</td>\n",
       "      <td>280000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>1405403694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>250000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>933959197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>Action</td>\n",
       "      <td>250000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>873260194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title      genre     budget  runtime  \\\n",
       "0                                    Avatar     Action  237000000    162.0   \n",
       "1  Pirates of the Caribbean: At World's End  Adventure  300000000    169.0   \n",
       "2                                   Spectre     Action  245000000    148.0   \n",
       "3                     The Dark Knight Rises     Action  250000000    165.0   \n",
       "4                               John Carter     Action  260000000    132.0   \n",
       "5                              Spider-Man 3    Fantasy  258000000    139.0   \n",
       "6                                   Tangled  Animation  260000000    100.0   \n",
       "7                   Avengers: Age of Ultron     Action  280000000    141.0   \n",
       "8    Harry Potter and the Half-Blood Prince  Adventure  250000000    153.0   \n",
       "9        Batman v Superman: Dawn of Justice     Action  250000000    151.0   \n",
       "\n",
       "   year  month     revenue  \n",
       "0  2009     12  2787965087  \n",
       "1  2007      5   961000000  \n",
       "2  2015     10   880674609  \n",
       "3  2012      7  1084939099  \n",
       "4  2012      3   284139100  \n",
       "5  2007      5   890871626  \n",
       "6  2010     11   591794936  \n",
       "7  2015      4  1405403694  \n",
       "8  2009      7   933959197  \n",
       "9  2016      3   873260194  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/decision-trees-intro/master/4-ds-concepts-4/imdb_movies.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data is a little bit different than the data we first worked with.  Here's why.  \n",
    "\n",
    "### The `budget` feature is continuous\n",
    "\n",
    "Notice that there is almost a different value for every feature value in our feature of `budget`.  So how can we split on a feature like this?  \n",
    "\n",
    "Well this time, our model will look at each different budget value, and use it as a split point.  So it will split all of the observations by those with a budget lower than `237000000` (the first budget value), and then greater or equal to `237000000`, and then move onto the next budget value, seeing how well the second budget serves as a split point.\n",
    "\n",
    "If such a split does a good job of splitting the data into movies with similar revenues, then it's chosen as a split for the data.  So this is how a decision tree can work with continuous features.  It tries splitting by each observed value in a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training On Continuous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stick with splitting the data by the movie budget.  And let's say our split is that all of the movies with a budget under 10 million are in one group, and all of the movies with a budget over 10 million are in a different group.  Did this do a good job of separating our data?  How do we rank our splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at two potential splits, movies with a budget under and over 10 million, and another split at 15 million dollar budgets.  Which split does a better job at grouping the (imaginary) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ten_million_under = [200, 250, 270]\n",
    "split_ten_million_over = [500, 600, 700, 900]\n",
    "\n",
    "split_fifteen_million_under = [200, 250, 270, 500, 600]\n",
    "split_fifteen_million_over = [700, 900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it looks the first split does a better job, as it produces that first group with revenues all close together.  But how do we quantify this? Remember that previously we said that our cost function was to count up the number of values placed into a mixed group.  But here every value in both splits is in a mixed group.  Does this mean they each do an equally good job.\n",
    "\n",
    "No, it means that we probably should use a different cost function.  Let's change our cost function to use the mean squared error.  \n",
    "\n",
    "Mean squared error just measures how close the datapoints are to the mean of the group.  The smaller the mean squared error, the closer the data is to the mean, and thus the better the split -- as the split is finding target data that is more tightly bunched together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this by way of example.  We'll start by calculating the mean squared error for the split of a 10 million dollar budget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(targets): \n",
    "    return sum(targets)/len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split_ten_million_a = [200, 250, 270]\n",
    "mean_ten_mil = calc_mean(split_ten_million_under)\n",
    "mean_ten_mil\n",
    "# 240.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking, we can already see that the numbers in `split_ten_million_a`, hover pretty close to the mean of 240.  But we can calculate this officially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_diffs(targets):\n",
    "    return [(target_val - calc_mean(targets))**2 for target_val in targets]\n",
    "\n",
    "def mse(targets):\n",
    "    diffs = squared_diffs(targets)\n",
    "    return sum(diffs)/len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866.6666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(split_ten_million_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then looking at the `mse` for the observations with a budget over 10 million we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21875.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(split_ten_million_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So splitting by movies below and above ten million gives us a different `mse` for each group.  How do we know how good this split was in total?  We can weight the `mse` scores by the amount of data in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12871.142857142857"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3/7)*866 + (4/7)*21875.0\n",
    "# 12871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we so we have a total `cost` of 12871.  The lower the cost the better the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this with our second split of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fifteen_million_under = [200, 250, 270, 500, 600]\n",
    "split_fifteen_million_over = [700, 900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24584.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(split_fifteen_million_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(split_fifteen_million_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take the weighted sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20417.142857142855"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5/7)*24584 + (2/7)*10000 \n",
    "# 20417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first split produced data that was more close together, so that split is better, according to our criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the details of mean squared error is only moderately important.  The important part is that we are able to quantify how close together a collection of data is: the smaller the combined mean squared error, the closer together the data.  So when we split our data, we choose the split that results in the lowest weighted sum of the mean squared error.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with Continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we got a sense of how to train on data that has a continuous target.  We use a cost function that calculates how closely bunched together the resulting subgroups are -- like mean squared error.  The smaller the mean squared error, the more closely the data is centered around the mean.  \n",
    "\n",
    "But once we train our decision tree, when our split places targets of different values in a single leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, let's say that splitting our data based on budget was one of the last splits in the decision tree. That is, that the split resulted in two leaf nodes, where we have the following two subgroups of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ten_million_under = [200, 250, 270]\n",
    "split_ten_million_over = [500, 600, 700, 900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's say that we get a a new observation that ends up in the leaf node for those with budgets under 10 million.  How do we predict this observation's revenue?\n",
    "\n",
    "We just calculate the mean of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean(split_ten_million_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we predict this observation will have a revenue of 240, as that is the average of the leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about working with continuous datasets.  We saw that for our features, we can still separate our data, as we'll choose split points at each observed value and determine how well it separates our data.\n",
    "\n",
    "Then, for our continuous target data, we saw that we can use the mean squared error to calculate how closely grouped together our data is after a split.  The lower the mean squared error, the closer together the data, and the better the split.  \n",
    "\n",
    "Finally, we saw that for continuous target data, we can still make a prediction for an observation that falls into a group - the prediction is simply the mean of the target values who fell into that group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change this to first talk about how the hypothesis function changes \n",
    "* Then how training changes with continuous data\n",
    "    * With our cost function\n",
    "    * Also add in the latex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
